# -*- coding: utf-8 -*-
"""Project Vehicle dataset from cardekho end to end

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1epjwg_BBW94iv2ADIsQp8jBCYhD5grmT
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

df = pd.read_csv("car data.csv")
df.head()

df.shape

print(df["Seller_Type"].unique())
print(df["Transmission"].unique())
print(df["Owner"].unique())

# check missing values
df.isnull().sum()

df.describe()

df["how_old"] = 2020 - df["Year"]

df.head()

df.drop(["Car_Name"],axis=1,inplace=True)

df.drop(["Year"],axis=1,inplace=True)

df.head()

df.columns

final_dataset = pd.get_dummies(df,drop_first=True)

final_dataset.head()

final_dataset.corr()

plt.figure(figsize=(15,15))
sns.heatmap(final_dataset.corr(), cmap="RdYlGn")

import warnings
warnings.filterwarnings('ignore')

# sns.pairplot(final_dataset, hue="Selling_Price")

X = final_dataset.drop(["Selling_Price"],axis=1)
y = final_dataset["Selling_Price"]

"""# Feature importance"""

from sklearn.tree import ExtraTreeRegressor
model = ExtraTreeRegressor()
model.fit(X,y)

model.feature_importances_

feat_imp = pd.DataFrame(model.feature_importances_, index=X.columns)
feat_imp.sort_values(0)

feat_imp.sort_values(0).plot(kind="bar")

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)

X_train.shape

"""# Model"""

from sklearn.ensemble import RandomForestRegressor
rfr = RandomForestRegressor()

# Hyperparameter
n_estimators=[int(x) for x in np.linspace(100,1200,12)]
max_features = ["auto","sqrt"]
max_depth=[int(x) for x in np.linspace(5,30,6)]
min_samples_split=[2,5,10,15,100]
min_samples_leaf=[1,2,5,10]

from sklearn.model_selection import RandomizedSearchCV

# creating a grid
random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf}

print(random_grid)

rscv = RandomizedSearchCV(rfr, param_distributions=random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)

rscv.fit(X_train,y_train)

rscv.best_params_

rscv.best_score_

rscv.best_estimator_

predictions = rscv.predict(X_test)

sns.distplot(y_test-predictions)

plt.scatter(y_test,predictions)

from sklearn import metrics

print('MAE:', metrics.mean_absolute_error(y_test, predictions))
print('MSE:', metrics.mean_squared_error(y_test, predictions))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))

import pickle
# open a file, where you ant to store the data
file = open('random_forest_regression_model.pkl', 'wb')

# dump information to that file
pickle.dump(rscv, file)


